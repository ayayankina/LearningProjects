# -*- coding: utf-8 -*-
"""ДЗ_Янкина_Алёна.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1GzgTQGYjgydb_iYtDqXhBQ4wrBbQ5jU3
"""

import torch
from torchvision import datasets, transforms
import matplotlib.pyplot as plt
import numpy as np

train_data = datasets.MNIST(root = './NN_torch_simple/.', train = True, download = True, transform = transforms.ToTensor())
test_data = datasets.MNIST(root = './NN_torch_simple/.', train = False, download = True, transform = transforms.ToTensor())

train_loader = torch.utils.data.DataLoader(train_data,batch_size = 16, shuffle = True)
test_loader = torch.utils.data.DataLoader(test_data,batch_size = len(test_data), shuffle = False)

dataiter = iter(train_loader)
images, labels = next(dataiter)

def show_images(img,labels):
    f, axes = plt.subplots(1,10,figsize = (30,5))
    for i,axis in enumerate(axes):
        axes[i].imshow(np.squeeze(np.transpose(img[i].numpy(),(1,2,0))))
        axes[i].set_title(labels[i].numpy())
    plt.show()

show_images(images,labels)

import torch.nn as nn
import torch.nn.functional as F

class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()         #(w,h) = (mW - kW + 1, mH - kH + 1)
        self.conv1 = nn.Conv2d(1, 16, 3)    #(28-3+1,26)
        self.conv2 = nn.Conv2d(16, 32, 3)   #(24,24)
        self.pool1 = nn.MaxPool2d(2)        #(23,23)
        self.pool2 = nn.MaxPool2d(2)        #(22,22)
        self.fc1 = nn.Linear(32*3*3, 120)
        self.fc2 = nn.Linear(120, 84)
        self.fc3 = nn.Linear(84, 10)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        x = self.pool1(x)
        x = F.relu(self.conv2(x))
        x = self.pool2(x)
        x = x.view(-1, 288)
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        x = self.fc3(x)
        return x
net = Net()

net

import torch.optim as optim

loss_net = nn.CrossEntropyLoss()
lr = 0.001
optimizer = torch.optim.Adam(net.parameters(), lr = lr)

epoch = 6

for epoch in range(epoch):

    running_loss = 0.0

    train_dataiter = iter(train_loader)

    for i, batch in enumerate(train_dataiter):
        X_batch, y_batch = batch

        optimizer.zero_grad()

        y_pred = net(X_batch)

        loss = loss_net(y_pred, y_batch)

        loss.backward()
        optimizer.step()

        running_loss += loss.item()

        if i%250 == 249:
            print(epoch +1,i+1, running_loss/250)
            running_loss = 0.0

print('DONE')

test_dataiter = iter(test_loader)
images,labels = next(test_dataiter)

show_images(images,labels)

predict_classes = np.argmax(net.forward(images).detach().numpy(), axis =1)

list(map(lambda x: x, predict_classes))[:10]

from sklearn.metrics import accuracy_score

test_dataiter = iter(test_loader)
images,labels = next(test_dataiter)
predict_classes = np.argmax(net.forward(images).detach().numpy(), axis =1)
accuracy_score(labels.numpy(), predict_classes)
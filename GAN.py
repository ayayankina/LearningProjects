# -*- coding: utf-8 -*-
"""СР_Янкина_Алёна_Алексеевна.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1X_m1Sec9il93m15acmuug6rhgCgAXhiR

# Самостоятельная работа
## Майнор НСТ
### Дедлайн 30.11.2024 23:59
### Загрузите работу в форму по ссылке закрепленной в конференции группы майнора

# Задание
1. Реализайте архитектуру GAN на датасете FashionMNIST, где генератор будет написан на архитектуре сверточной сети
2. Реализуйте архитектуру сверточной нейронной сети, которая будет обучена на датасете FashionMNIST, для классификации ваших сгенерированных изображений
3. Прокомментировать цикл обучения (дать комментарии кода процесса обучения)

# Оценка будет снижена, если
1) Архитектура генератора написана без использование сверточных слоев
2) Обучение модели написано не для GPU
3) Нет никаких комментариев в работе

# Оценивание
### 8 балов за задание(1) и 2 бала за задание(2)

### Задание можно выполнить на датасете MNIST
### НО, тогда градация балов будет: 5 за задание(1) и 2 за задание(2)

# 1.
"""

import torchvision
import torchvision.transforms as transforms
import torch
import matplotlib.pyplot as plt
from torch import nn

torch.manual_seed(123)

transform = transforms.Compose([
transforms.Resize(64),
transforms.ToTensor(),
transforms.Normalize((0.5,), (0.5,)),
])

train_set = torchvision.datasets.FashionMNIST(root='./', download = True, train =True, transform = transform)

batch_size = 32
train_loader = torch.utils.data.DataLoader(train_set,batch_size = batch_size, shuffle = True)

# посмотрим примеры картинок в датасете
real_samples, labels = next(iter(train_loader))

for i in range(4):
  ax = plt.subplot(4,4,i+1)
  plt.imshow(real_samples[i].reshape(64, 64), cmap = 'gray_r')

# модель дискриминатора со сверточной архитектурой
class D(nn.Module):
    def __init__(self, image_channels, features):
        super(D, self).__init__()
        self.model = nn.Sequential(
            nn.Conv2d(image_channels, features, kernel_size=4, stride=2, padding=1),
            nn.LeakyReLU(0.2),

            nn.Conv2d(features, features*2, kernel_size=4, stride=2, padding=1),
            nn.BatchNorm2d(features*2),
            nn.LeakyReLU(0.2),

            nn.Conv2d(features*2, features*4, kernel_size=4, stride=2, padding=1),
            nn.BatchNorm2d(features*4),
            nn.LeakyReLU(0.2),

            nn.Conv2d(features*4, features*8, kernel_size=4, stride=2, padding=1),
            nn.BatchNorm2d(features*8),
            nn.LeakyReLU(0.2),

            nn.Conv2d(features*8, 1, kernel_size=4, stride=2, padding=0),
            nn.Sigmoid(),
        )

    def forward(self, x):
        return self.model(x)

# модель генератора со сверточной архитектурой
class G(nn.Module):
    def __init__(self, noise_channels, image_channels, features):
        super(G, self).__init__()
        self.model = nn.Sequential(
            nn.ConvTranspose2d(noise_channels, features*16, kernel_size=4, stride=1, padding=0),
            nn.ReLU(),

            nn.ConvTranspose2d(features*16, features*8, kernel_size=4, stride=2, padding=1),
            nn.BatchNorm2d(features*8),
            nn.ReLU(),

            nn.ConvTranspose2d(features*8, features*4, kernel_size=4, stride=2, padding=1),
            nn.BatchNorm2d(features*4),
            nn.ReLU(),

            nn.ConvTranspose2d(features*4, features*2, kernel_size=4, stride=2, padding=1),
            nn.BatchNorm2d(features*2),
            nn.ReLU(),

            nn.ConvTranspose2d(features*2, image_channels, kernel_size=4, stride=2, padding=1),
            nn.Tanh(),
        )

    def forward(self, x):
        return self.model(x)

image_channels = 1
noise_channels = 256
gen_features = 64
disc_features = 64

device = 'cuda' if torch.cuda.is_available() else 'cpu'

generator = G(noise_channels, image_channels, gen_features).to(device)
discriminator = D(image_channels, disc_features).to(device)

# настраиваем гиперпараметры
num_epoch = 50
lr = 0.0005
loss_function = nn.BCELoss()

optimizer_d = torch.optim.Adam(discriminator.parameters(),lr=lr, betas=(0.5, 0.999))
optimizer_g = torch.optim.Adam(generator.parameters(),lr=lr, betas=(0.5, 0.999))

for epoch in range(num_epoch):
    for batch_idx, (data, target) in enumerate(train_loader):
        # переносим данные в cuda
        data = data.to(device)

        batch_size = data.shape[0]

        # учим модель дискриминатора на реальных данных
        discriminator.zero_grad()
        # создаем метку для реальных данных
        label = (torch.ones(batch_size) * 0.9).to(device)
        output = discriminator(data).reshape(-1)
        real_disc_loss = loss_function(output, label)
        d_x = output.mean().item()

        # учим модель дискриминатора на сгенерированных данных

        # генерация фальшивых данных
        noise = torch.randn(batch_size, noise_channels, 1, 1).to(device)
        fake = generator(noise)
        # метка для фальшивых данных
        label = (torch.ones(batch_size) * 0.1).to(device)
        output = discriminator(fake.detach()).reshape(-1)
        fake_disc_loss = loss_function(output, label)

        # считаем суммарную ошибку дискриминатора
        disc_loss = real_disc_loss + fake_disc_loss

        # обновляем параметры дискриминатора
        disc_loss.backward()
        optimizer_d.step()

        # учим модель генератора
        generator.zero_grad()
        label = torch.ones(batch_size).to(device)
        output = discriminator(fake).reshape(-1)
        gen_loss = loss_function(output, label)

        # обновляем параметры генератора
        gen_loss.backward()
        optimizer_g.step()

        # выводим ошибку на текущую эпоху
        if batch_idx == len(train_loader) - 1:
          print(f'{epoch} LOSS D: {disc_loss}')
          print(f'{epoch} LOSS G: {gen_loss}')

"""Выполнение кода было прервано вручную, так как он слишком долго обучался и было принято решение, что текущего обучения уже достаточно для генерации адеватных картинок.


"""

# посмотрим на примеры сгенерированных картинок
noise_samples = torch.randn(batch_size, noise_channels, 1, 1).to(device)
generated_samples = generator(noise_samples)
generated_samples = generated_samples.detach().cpu()

for i in range(4):
  ax = plt.subplot(4,4,i+1)
  plt.imshow(generated_samples[i].reshape(64,64), cmap = 'gray_r')

"""# 2."""

test_set = torchvision.datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=False, transform=transform)
test_loader = torch.utils.data.DataLoader(test_set, batch_size=64, shuffle=True)

# проверяем размер картинок
a = next(iter(train_loader))
a[0].size()

# соответствия меток классов
def output_label(label):
    output_mapping = {
                 0: "T-shirt/Top",
                 1: "Trouser",
                 2: "Pullover",
                 3: "Dress",
                 4: "Coat",
                 5: "Sandal",
                 6: "Shirt",
                 7: "Sneaker",
                 8: "Bag",
                 9: "Ankle Boot"
                 }
    input = (label.item() if type(label) == torch.Tensor else label)
    return output_mapping[input]

# проверяем соответствие метки
image, label = next(iter(train_set))
plt.imshow(image.squeeze(), cmap="gray")
print(label)

# модель классификации со сверточной архитектурой
class FashionCNN(nn.Module):
    def __init__(self):
        super(FashionCNN, self).__init__()

        self.layer1 = nn.Sequential(
            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1),
            nn.BatchNorm2d(32),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2)  # 64x64 -> 32x32
        )

        self.layer2 = nn.Sequential(
            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2)  # 32x32 -> 16x16
        )

        self.layer3 = nn.Sequential(
            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2)  # 16x16 -> 8x8
        )

        self.fc1 = nn.Linear(in_features=128*8*8, out_features=600)  # входные признаки: 128*8*8
        self.drop = nn.Dropout2d(0.25)
        self.fc2 = nn.Linear(in_features=600, out_features=120)
        self.fc3 = nn.Linear(in_features=120, out_features=10)

    def forward(self, x):
        out = self.layer1(x)
        out = self.layer2(out)
        out = self.layer3(out)
        out = out.view(out.size(0), -1)
        out = self.fc1(out)
        out = self.drop(out)
        out = self.fc2(out)
        out = self.fc3(out)

        return out

learning_rate = 0.001

model = FashionCNN()
model.to(device)

error = nn.CrossEntropyLoss()

optimizer_cl = torch.optim.Adam(model.parameters(), lr=learning_rate)
print(model)

num_epochs = 10
count = 0

# обучение
for epoch in range(num_epochs):
    for images, labels in train_loader:
        images, labels = images.to(device), labels.to(device)

        train = images.view(32, 1, 64, 64)
        labels = labels

        outputs = model(train)
        loss = error(outputs, labels)

        optimizer_cl.zero_grad()
        loss.backward()
        optimizer_cl.step()

        count += 1

    # тест модели

        if not (count % 50):
            total = 0
            correct = 0

            for images, labels in test_loader:
                images, labels = images.to(device), labels.to(device)

                test = images.view(images.size(0), 1, 64, 64)

                outputs = model(test)

                predictions = torch.max(outputs, 1)[1].to(device)
                correct += (predictions == labels).sum()

                total += len(labels)

            accuracy = correct * 100 / total

        if not (count % 500):
            print("Iteration: {}, Loss: {}, Accuracy: {}%".format(count, loss.data, accuracy))

"""Выполнение кода было прервано вручную, так как он слишком долго обучался, а обучение начало стагнировать."""

noise_samples = torch.randn(batch_size, noise_channels, 1, 1).to(device)
generated_samples = generator(noise_samples)
generated_samples = generated_samples.detach().to(device)

predicted_labels = model(generated_samples)

# предсказание классов
_, predicted_classes = torch.max(predicted_labels, 1)

plt.figure(figsize=(2, 3))
for i in range(4):
    ax = plt.subplot(2, 2, i + 1)
    plt.imshow(generated_samples[i].reshape(64, 64).cpu(), cmap='gray_r')
    plt.axis('off')
    class_name = output_label(predicted_classes[i])
    plt.title(f"{class_name} ({predicted_classes[i].item()})", fontsize=10)

plt.tight_layout()
plt.show()